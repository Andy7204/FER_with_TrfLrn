# -*- coding: utf-8 -*-
"""Emotion Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TSIK5XIxnXlmJOU06LZVnqebqqOBiKW5
"""

# Emotion Prediction
import cv2
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

# Label mapping dictionary
label_map = {
    0: 'anger',
    1: 'fear',
    2: 'happiness',
    3: 'sadness',
    4: 'surprise',
    5: 'neutral'
}

def detect_face(image_path):
    # Load the pre-trained Haar Cascade classifier for face detection
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Read the input image
    image = cv2.imread(image_path)
    if image is None:
        raise FileNotFoundError(f"Image file '{image_path}' not found.")

    # Convert the image to grayscale (face detection works on grayscale images)
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Detect faces in the grayscale image
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    cropped_faces = []

    # Iterate over detected faces
    for (x, y, w, h) in faces:
        # Draw rectangle around the face
        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)

        # Crop the face region from the image
        cropped_face = image[y:y+h, x:x+w]
        cropped_faces.append(cropped_face)

    plt.figure(figsize=(8, 6))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.title(f'Detected {len(cropped_faces)} Faces')
    plt.show()

    return cropped_faces

# Function to predict emotion from a cropped face image using a pre-trained model
def predict_emotion(face_image, model_path):
    # Load the saved model from HDF5 file
    model = tf.keras.models.load_model(model_path)

    # Resize to your model's input shape (224x224) and normalize
    resized_image = cv2.resize(face_image, (224, 224)) / 255.0

    # Expand dimensions to match the input shape for the model
    input_image = np.expand_dims(resized_image, axis=0)

    # Make predictions
    predictions = model.predict(input_image)

    # Get the index of the highest probability prediction
    predicted_index = np.argmax(predictions[0])

    # Get the label and probability
    predicted_label = label_map[predicted_index]
    predicted_probability = float(predictions[0][predicted_index])

    return predicted_label, predicted_probability

# Example usage
model_path = '/kaggle/input/my_model/tensorflow2/v1/1/vgg19.h5'
input_image_path = '/kaggle/input/testing-data-realtime/HA_1.jpg'

# Detect and crop the faces from the input image
cropped_faces = detect_face(input_image_path)

# Predict emotion for each cropped face
for i, cropped_face in enumerate(cropped_faces):
    label, prob = predict_emotion(cropped_face, model_path)
    print(f"Face {i+1}: Emotion - {label}, Confidence - {prob:.4f}")